%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% AMS Beamer series / Bologna FC / Template
% Andrea Omicini
% Alma Mater Studiorum - Universit√† di Bologna
% mailto:andrea.omicini@unibo.it
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\documentclass[handout]{beamer}\mode<handout>{\usetheme{default}}
%
\documentclass[presentation, 9pt]{beamer}\mode<presentation>{\usetheme{AMSBolognaFC}}
%\documentclass[handout]{beamer}\mode<handout>{\usetheme{AMSBolognaFC}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[T1]{fontenc}
\usepackage{wasysym}
\usepackage{amsmath,blkarray}
\usepackage[minted,most]{tcolorbox}
\usepackage{centernot}
\usepackage{fontawesome}
\usepackage{fancyvrb}
\setminted[scala]{fontsize=\scriptsize,baselinestretch=1,obeytabs=true, tabsize=2}
\usepackage[ddmmyyyy]{datetime}
\definecolor{darkcyan}{rgb}{0.0, 0.55, 0.55}
\renewcommand{\dateseparator}{}
%\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\newcommand{\version}{1}
\usepackage[
	backend=biber,
	citestyle=authoryear-icomp,
	maxcitenames=1,
	bibstyle=numeric]{biblatex}

	\makeatletter

\addbibresource{biblio.bib}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title[Period Abroad Recap]
{Period Abroad Recap}
%
\subtitle[Graph Neural Networks and Spatio-Temporal tracking]
{Graph Neural Networks and Spatio-Temporal tracking}
%
\author[\sspeaker{Aguzzi}]
{\speaker{Gianluca Aguzzi} \href{mailto:gianluca.aguzzi@unibo.it}{gianluca.aguzzi@unibo.it}}
%
\institute[DISI, Univ.\ Bologna]
{Dipartimento di Informatica -- Scienza e Ingegneria (DISI)\\
\textsc{Alma Mater Studiorum} -- Universit{\`a} di Bologna \\[0.5cm]
}
%
\renewcommand{\dateseparator}{/}
\date[\today]{\today}
%
\AtBeginSection[]
{
  \begin{frame}
  \frametitle{Contents}
  \tableofcontents[currentsubsection, 
	sectionstyle=show/shaded, 
	subsectionstyle=show/shaded]
  \end{frame}
}
\AtBeginSubsection[]
{
  \begin{frame}
  \frametitle{Contents}
  \tableofcontents[currentsubsection, 
	sectionstyle=show/shaded, 
	subsectionstyle=show/shaded]
  \end{frame}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%/////////
\frame{\titlepage}
%/////////

%===============================================================================
\section{Introduction}
\begin{frame}{Activities -- One slide}
\begin{itemize}
	\item \bold{Main idea}: spatio-temporal tracking of a natural phenomenon
	\begin{itemize}
		\item Generation of synthetic data (moving boids)
		\item Studying of spatio-temporal neural network models (forecast)
		\begin{itemize}
			\item Graph Neural Networks
			\item Reccurrent Neural Networks
			\item \emph{Recurrent Graph Neural Networks}
		\end{itemize}
		\item Training GNNs through PyTorch and data generated from Alchemist
		\item Integrate Neural networks with Aggregate Computing
		\item Use forecast to compute the best path for nodes
	\end{itemize}
	\item \bold{Clustering}: continue the idea of swarm-based clustering -- avoid the leader election phase
	\begin{itemize}
		\item Inside the cluster, compute the leader (bounded leader election)
	\end{itemize}
\end{itemize}
\end{frame}
%===============================================================================

%===============================================================================
\section{Graph Neural Networks}
\begin{frame}{Artificial Neural Networks -- Recap}
\begin{alertblock}{Definition}
	Collection of units (also called \emph{artificial neuron}) that simulates the behavior of biological neurons
	connected by weighted edges (also called \emph{synapses}).
\end{alertblock}
\begin{itemize}
	\item Typical organization: \emph{input layer}, \emph{hidden layers}, \emph{output layer}
	\item Each layer is composed by a set of neurons
	\item The output of each layer is computed as: $[y = f(\sum_{i=1}^n w_i x_i)]$ where $f$ is the activation function
	\item The way in which the neurons are connected is called \emph{topology}
	\item The are several topology types:
	\begin{itemize}
		\item Fully connected (MLP): standard neural network, used for classification and regression problem 
		\item Convolutional: used for image processing
		\item Recurrent: used for time series prediction
		\item \bold{Graph Neural Networks}: used for graph processing
	\end{itemize}
\end{itemize}
\end{frame}
%===============================================================================
\begin{frame}{Graph Neural Networks}
\begin{alertblock}{Definition}
	A graph neural network (GNN)~\scite{scarselli2008graph} is a neural network that operates on \textit{graphs}
\end{alertblock}
\begin{itemize}
	\item \bold{Tasks}
	\begin{itemize}
		\item Node classification: given a graph $G=(V,E)$ and a set of labels $X$, predict the label of each node $v \in V$
		\item Link regression: given a graph $G=(V,E)$ and a set of labels $X$, predict the label of each edge $(u,v) \in E$
		\item Graph classification/regression: given a graph $G=(V,E)$ and a set of labels $X$, predict the label of the graph
	\end{itemize}
	\item \bold{Applications}
	\begin{itemize}
		\item \emph{Representation learning}
		\item \emph{Traffic forecast}~\scite{jiang2022graph}
		\item Physics simulations~\scite{jiang2022graph}
		\item Recommandation systems~\scite{wu2020graph}
		\item Chemistry (Molecular fingerprint, chemical reaction)~\scite{zhou2020graph}
		\item Stock market~\scite{matsunaga2019exploring}
		\item Program verification~\scite{NEURIPS2019_49265d24}
		\item ...
	\end{itemize}
	\item Amazing gentle introduction: 
	\begin{itemize}
		\item \url{https://distill.pub/2021/gnn-intro/}
		\item \url{https://tkipf.github.io/graph-convolutional-networks/}
	\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{GNN structure \& dynamics}
	\begin{itemize}
		\item \bold{Idea}: iteratively update the node representations 
		by combining the representations of their neighbors and their own representations
		\item \bold{K}: layer of GNNs
		\item \bold{$H^i$}: node representations at layer i ($H^0 = X$)
		\item each layer:
		\begin{itemize}
			\item aggregate the information from the neighbors of each node (\textbf{AGGREGATE} phase) $\sim$ \bold{\lstinline|nbr|}
			\item update the node representations by combining the aggregated information from neighbors with the current node representations (\textbf{COMBINE}) $\sim$ \bold{\lstinline|foldhood|}
		\end{itemize}
		\item Matematically:
			$$
			\begin{array}{l}
			a_v^k=\text{AGGREGATE}^k\left\{H_u^{k-1}: u \in N(v)\right\} \\
			H_v^k=\mathbf{COMBINE}^k\left\{H_v^{k-1}, a_v^k\right\},
			\end{array}
			$$
		\item $N(v)$: neighborhood of node $v$
		\item \textbf{AGGREGATE} could be: \textbf{sum}, \textbf{mean}, \textbf{max}, \textbf{min}, \textbf{attention}, etc.
		\item \textbf{COMBINE} could be: \textbf{concatenation}, \textbf{addition}, \textbf{neural network}, etc.
		\item Several architecture are proposed, changing the \textbf{AGGREGATE} and \textbf{COMBINE} functions:
		\begin{itemize}
			\item Graph Convolutional Networks (GCN)~\cite{kipf2016semi}
			\item Graph SAGE~\cite{hamilton2017inductive}
		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{GNN structure \& dynamics}
	\includegraphics[width=\textwidth]{img/example-gnn.png}
	\begin{itemize}
		\item Aggregate computing execution model perspective:
		\begin{itemize}
			\item GNN updates the node representations in a \textbf{parallely} {\textcolor{darkcyan}\faThumbsUp} but globally synchronized {\textcolor{bolognafcred}\faThumbsDown}
			\begin{itemize}
				\item[{\textcolor{darkcyan}\faThumbsUp}] Despite that, GNN could be use for distributed computing
			\end{itemize} 
			\item Stacking several layers of GNNs, lead to several hops of information propagation
			\begin{itemize}
				\item Therefore, we could use at most one layer \faArrowRight \, no deep structure for graph representation
			\end{itemize}
		\end{itemize}
	\end{itemize}
\end{frame}

%===============================================================================
\section{Aggregate Computing + Neural Networks}
%===============================================================================


%===============================================================================
\section{Use case: spatio temporal forecast + tracking}
%===============================================================================


%===============================================================================
\section{Clustering}
%===============================================================================


%===============================================================================
\section*{}
%===============================================================================

%/////////
\frame{\titlepage}
%/////////

%===============================================================================
\section*{\refname}
%===============================================================================

%%%%
\setbeamertemplate{page number in head/foot}{}
%/////////
\begin{frame}[c,noframenumbering, allowframebreaks]{\refname}
%\begin{frame}[t,allowframebreaks,noframenumbering]{\refname}
	\tiny
	\printbibliography
\end{frame}
%/////////

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
